<!DOCTYPE html>
<html>
<head>
  <title>Zhifan Zhu, PhD student at University of Bristol</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      max-width: 1200px;
      padding: 20px;
    }

    h1 {
      font-size: 36px;
      margin-bottom: 20px;
    }

    h2 {
      font-size: 24px;
      margin-bottom: 15px;
    }

    p {
      font-size: 18px;
      line-height: 1.5;
      margin-bottom: 10px;
    }

    li {
      margin: 0;
      padding: 0.2em;
    }

    a {
      color: blue;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }


    /*
    .tooltip {
      position: relative;
      display: inline-block;
    }
    .tooltip .tooltiptext {
      visibility: hidden;
      position: absolute;
      top: 0%;
      left: 120%;

      width: 600px;
      padding: 8px 16px;

      background: white;
      border: 1px dashed black;
      color: black;
      text-align: center;

      opacity: 0;
      transition: opacity 0.2s;
    }
    .tooltip:hover .tooltiptext {
      visibility: visible;
      opacity: 1;
    }
      */

    .egoexo4d-tooltip {
      font-size: 18px;
      position: relative;
      display: inline-block;
    }
    .egoexo4d-tooltip .egoexo4d-tooltiptext {
      font-size: 16px;
      visibility: hidden;
      background-color: white;
      color: black;
      text-align: center;
      border: 1px dashed black;
      position: absolute;
      z-index: 1;
      opacity: 0;
      transition: opacity 0s;
      top: 100%;
      left: 60%;
      width: 80%;
      padding: 0 24px;
      transition: opacity 0.3s;
    }
    .egoexo4d-tooltip:hover .egoexo4d-tooltiptext {
      visibility: visible;
      opacity: 1;
    }

  </style>
</head>
<body>
  <h1>Zhifan Zhu</h1>
  
  <p>
    I'm a PhD student in Computer Vision at the University of Bristol since Dec 2021, supervised by <a href="https://dimadamen.github.io">Prof. Dima Damen</a>.<br>
    My interests are in video(ordered images) understanding, egocentric vision and 3D reconstruction of dynamic objects and interactions.
  </p>
  <p>
    <a href="https://scholar.google.com/citations?user=9_7rBUIAAAAJ&hl=en&oi=ao">Google Scholar</a> | 
    <a href="https://twitter.com/zhifan_zhu">Twitter</a> | 
    <a href="mailto:zhifan.zhu-at-bristol.ac.uk">Email</a> | 
    <a href="https://github.com/zhifanzhu">GitHub</a> 
  </p>

  <h2>News</h2>
  <ul>
    <li> 
      I was recognised as an <a href="https://cvpr.thecvf.com/Conferences/2025/ProgramCommittee#all-outstanding-reviewer">Outstanding Reviewer</a> for CVPR 2025.
    </li>
    
    </li>
  </ul>

  <h2>Research</h2>

  <p>
    <b>The N-Body Problem: Parallel Execution from Single-Person Egocentric Video
    </b><br>
    <b>Zhifan Zhu</b>, Yifei Huang, Yoichi Sato, Dima Damen<br>
    <i>Arxiv</i>, 2025 <br>
    <a href="https://zhifanzhu.github.io/ego-nbody/">Webpage</a> |
    <a href="https://arxiv.org/abs">Arxiv (coming)</a>
    <!-- | <span class="tooltip"><i style="color: gray;">TL;DR</i>
      <span class="tooltiptext">
        If I invite a friend to my house, can we speed-up my work?
      </span>
    </span> -->
  </p>

  <p>
    <b>Reconstructing Objects along Hand Interaction Timelines in Egocentric Video
    </b><br>
    <b>Zhifan Zhu</b>, Siddhant Bansal, Shashank Tripathi, Dima Damen<br>
    <i>Arxiv</i>, 2025 <br>
    <a href="https://zhifanzhu.github.io/objects-along-hit/">Webpage</a> |
    <a href="https://arxiv.org/abs/2512.07394">Arxiv</a>
    <!-- |  <span class="tooltip"><i style="color: gray;">TL;DR</i>
      <span class="tooltiptext">
        A constrained optimisation framework that reconstructs object poses in egocentric video
      </span> -->
  </p>

  <p>
    <b>The Invisible EgoHand: 3D Hand Forecasting through EgoBody Pose Estimation
    </b><br>
    Masashi Hatano, <b>Zhifan Zhu</b>, Hideo Saito, Dima Damen<br>
    <i>Arxiv</i>, 2025 <br>
    <a href="https://masashi-hatano.github.io/EgoH4/">Webpage</a> | 
    <a href="https://arxiv.org/abs/2504.08654">Arxiv</a>
  </p>

  <p>
    <b>HD-EPIC: A Highly-Detailed Egocentric Video Dataset</b><br>
    Toby Perrett*, Ahmad Darkhalil*, Saptarshi Sinha*, Omar Emara*, Sam Pollard*, Kranti Parida*, Kaiting Liu*, 
    Prajwal Gatti*, Siddhant Bansal*, Kevin Flanagan*, Jacob Chalk*, 
    <b>Zhifan Zhu*</b>, Rhodri Guerrier*, Fahd Abdelazim*, 
    Bin Zhu, Davide Moltisanti, Michael Wray, Hazel Doughty, Dima Damen<br>
      <i>CVPR</i>, 2025 <br>
      <a href="https://hd-epic.github.io/">Webpage</a> | 
      <a href="https://arxiv.org/abs/2502.04144">Arxiv</a>
    </p>

  <p>
  <b>Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives</b><br>
  <span class="egoexo4d-tooltip">Kristen Grauman, Andrew Westbury, Lorenzo Torresani, Kris Kitani, Jitendra Malik, [and 95 others, including <b>Zhifan Zhu</b>]
    <span class="egoexo4d-tooltiptext">
      Kristen Grauman, Andrew Westbury, Lorenzo Torresani, Kris Kitani, Jitendra Malik, Triantafyllos Afouras, Kumar Ashutosh, Vijay Baiyya, Siddhant Bansal, Bikram Boote, Eugene Byrne, Zach Chavis, Joya Chen, Feng Cheng, Fu-Jen Chu, Sean Crane, Avijit Dasgupta, Jing Dong, Maria Escobar, Cristhian Forigua, Abrham Gebreselasie, Sanjay Haresh, Jing Huang, Md Mohaiminul Islam, Suyog Jain, Rawal Khirodkar, Devansh Kukreja, Kevin J Liang, Jia-Wei Liu, Sagnik Majumder, Yongsen Mao, Miguel Martin, Effrosyni Mavroudi, Tushar Nagarajan, Francesco Ragusa, Santhosh Ramakrishnan, Luigi Seminara, Arjun Somayazulu, Yale Song, Shan Su, Zihui Xue, Edward Zhang, Jinxu Zhang, Angela Castillo, Changan Chen, Xinzhu Fu, Ryosuke Furuta, Cristina Gonzalez, Prince Gupta, Jiabo Hu, Yifei Huang, Yiming Huang, Weslie Khoo, Anush Kumar, Robert Kuo, Sach Lakhavani, Miao Liu, Mi Luo, Zhengyi Luo, Brighid Meredith, Austin Miller, Oluwatumininu Oguntola, Xiaqing Pan, Penny Peng, Shraman Pramanick, Merey Ramazanova, Fiona Ryan, Wei Shan, Kiran Somasundaram, Chenan Song, Audrey Southerland, Masatoshi Tateno, Huiyu Wang, Yuchen Wang, Takuma Yagi, Mingfei Yan, Xitong Yang, Zecheng Yu, Shengxin Cindy Zha, Chen Zhao, Ziwei Zhao, <b>Zhifan Zhu</b>, Jeff Zhuo, Pablo Arbelaez, Gedas Bertasius, David Crandall, Dima Damen, Jakob Engel, Giovanni Maria Farinella, Antonino Furnari, Bernard Ghanem, Judy Hoffman, C. V. Jawahar, Richard Newcombe, Hyun Soo Park, James M. Rehg, Yoichi Sato, Manolis Savva, Jianbo Shi, Mike Zheng Shou, Michael Wray
    </span>
  </span><br>
    <i>CVPR</i>, 2024 <br>
    <a href="https://ai.meta.com/blog/ego-exo4d-video-learning-perception/">Blog</a> | 
    <a href="https://ego-exo4d-data.org/paper/ego-exo4d-supp.pdf">PDF</a>
  </p>

  <p>
  <b>Get a Grip: Reconstructing Hand-Object Stable Grasps in Egocentric Videos</b><br>
    <b>Zhifan Zhu</b>, Dima Damen<br>
    <i>Arxiv</i>, 2024 <br>
    <a href="https://zhifanzhu.github.io/getagrip/">Webpage</a> | 
    <a href="https://arxiv.org/abs/2312.15719">Arxiv</a>
  </p>

  <p>
  <b>EPIC Fields: Marrying 3D Geometry and Video Understanding</b><br>
    Vadim Tschernezki*, Ahmad Darkhalil*, <b>Zhifan Zhu*</b>, David Fouhey, Iro Laina, Diane Larlus, Dima Damen, Andrea Vedaldi<br>
    <i>NeurIPS D&B</i>, 2023 <br>
    <a href="https://epic-kitchens.github.io/epic-fields/">Webpage</a> | 
    <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/543d4e171150cb931f1d401cacc3d7af-Abstract-Datasets_and_Benchmarks.html">Proceedings</a>
    | <a href="https://arxiv.org/abs/2306.08731">Arxiv</a>
    <!-- <a href="https://openreview.net/forum?id=1agtIRxlCY">OpenReview</a> -->
  </p>


  <h2>Miscellaneous</h2>
  <ul>
    <li> 
      April and May 2025, I was a visiting researcher at <a href="https://sites.google.com/ut-vision.org/ysato/">Prof. Yoichi Sato</a>'s lab (<a href="https://www.ut-vision.org/">Computer Vision Group</a>) at IIS, U-Tokyo.
      
    <li> 
      In August 2023, I attended the International Computer Vision Summer School <a href="https://iplab.dmi.unict.it/icvss2023/Home">(ICVSS 2023)</a> in Sicily, Italy.
    </li>

    <li>
      Visualising 3D rotation distributions.
      <a href="https://zhifanzhu.github.io/visualize-rotations">Webpage</a><br>
    </li>

    <li>
      3x3 Sudoku can be 
      <a href="https://zhifanzhu.github.io/boring-sudoku/">boring</a>.<br>
    </li>

    <li>
      Fourier Transform of N-Dimensional Gaussian Distribution.
      <a href="https://zhifanzhu.github.io/misc/Fourier_Transform_of_N_Dimensional_Gaussian.pdf">PDF</a>
    </li>
  </ul>

  <h2>Education</h2>
  <p>
    I obtained my master degree at the Nanjing University of Science and Technology in 2021, and my bachelor degree at the same university in 2018.
  </p>

  <h2>Teaching Experiences</h2>
  <p>
    COMSM0085 Overview of Software Tools, University of Bristol. 2022-2024<br>
    COMSM0045 Applied Deep Learning, University of Bristol. 2022-2024
  </p>

</body>
</html>
